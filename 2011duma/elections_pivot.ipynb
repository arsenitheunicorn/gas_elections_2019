{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloaden(link: str) -> (str):\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\n",
    "    req = urllib.request.Request(link, headers={'User-Agent': user_agent})\n",
    "    with urllib.request.urlopen(req) as resp:\n",
    "        html = resp.read()\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinksFromPivot(root_link):\n",
    "    html = downloaden(root_link)\n",
    "    output = {}\n",
    "    lines = str(html.decode('windows-1251')).split('\\n')\n",
    "    for line in lines:\n",
    "        if len(re.findall('href=', line)) > 3:\n",
    "            soup = BeautifulSoup(line, 'html.parser')\n",
    "            links = soup.find_all('a')\n",
    "            for link in links:\n",
    "                if re.search('>(.+?)<', str(link)):\n",
    "                    name = re.search('>(.+?)<', str(link)).group(1)\n",
    "                    href = link.get('href')\n",
    "                    output[name] = href\n",
    "            break\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getLinksFromPivot('http://www.vybory.izbirkom.ru/region/region/izbirkom?action=show&root=1&tvd=100100028713304&vrn=100100028713299&region=0&global=1&sub_region=0&prver=0&pronetvd=null&vibid=100100028713304&type=233')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bridgeToLocal(link, string='комиссии субъекта'):\n",
    "    html = downloaden(link)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "    output = ''\n",
    "    for link in links:\n",
    "        text = link.text\n",
    "        if string in text.strip():\n",
    "            output = link.get('href')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixItUp(details_dict, positions):\n",
    "    #positions.extend([20, 21, 22, 23, 24, 25, 26])\n",
    "    output = {}\n",
    "    uiks = details_dict[0]\n",
    "    for number, uik in enumerate(uiks):\n",
    "        wanted_list = []\n",
    "        for i in positions:\n",
    "            value = details_dict[i][number]\n",
    "            if '\\n' in value:\n",
    "                value = value.split('\\n')[0]\n",
    "            wanted_list.append(value)\n",
    "        output[uik] = wanted_list\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTable(link, positions):\n",
    "    html = downloaden(link)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    #meta = tables[-2].find_all('tr')\n",
    "    details = tables[-1].find_all('tr')\n",
    "    #meta_cells = [row.find_all('td') for row in meta]\n",
    "    details_cells = [row.find_all('td') for row in details]\n",
    "\n",
    "    #meta_f = {}\n",
    "#for row_id, row in enumerate(meta_cells):\n",
    "    #fertig = [cell.text.strip() for cell in row]\n",
    "    #meta_f[row_id] = fertig[1]\n",
    "    details_f = {}\n",
    "\n",
    "    for row_id, row in enumerate(details_cells):\n",
    "        fertig = [cell.text.strip() for cell in row]\n",
    "        details_f[row_id] = fertig\n",
    "    output = mixItUp(details_f, positions)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTable(region, wb):\n",
    "    with open('duma2013.csv', 'a') as f:\n",
    "        tiks = wb[region].keys()\n",
    "        for tik in tiks:\n",
    "            uiks = wb[region][tik].keys()\n",
    "            for uik in wb[region][tik]:\n",
    "                uik_n = 'УИК №' + uik[5:]\n",
    "                row = [region, tik, uik_n]\n",
    "                row.extend(wb[region][tik][uik])\n",
    "                try:\n",
    "                    f.write(';'.join(row))\n",
    "                except UnicodeEncodeError:\n",
    "                    print(row)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeta(link, positions):\n",
    "    html = downloaden(link)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    meta = tables[-2].find_all('tr')\n",
    "    meta_cells = [row.find_all('td') for row in meta]\n",
    "    \n",
    "    meta_f = []\n",
    "    for row_id, row in enumerate(meta_cells):\n",
    "        fertig = [cell.text.strip() for cell in row]\n",
    "        if row_id < 20:\n",
    "            meta_f.append(fertig[1])\n",
    "        else:\n",
    "            meta_f.append(fertig[1].split('партия ')[1].strip('\"'))\n",
    "    return meta_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(positions=[1,7,8,9,10], counter=0):\n",
    "    positions.extend([20, 21, 22, 23, 24, 25, 26])\n",
    "    root_pivot = 'http://www.vybory.izbirkom.ru/region/region/izbirkom?action=show&root=1&tvd=100100028713304&vrn=100100028713299&region=0&global=1&sub_region=0&prver=0&pronetvd=null&vibid=100100028713304&type=233'\n",
    "    oik_links = getLinksFromPivot(root_pivot)\n",
    "    print(len(oik_links))\n",
    "    oik_tik = {}\n",
    "    \n",
    "    if counter == 0:\n",
    "        fill = open('duma2013.csv', 'w')\n",
    "        starter = 0\n",
    "    else:\n",
    "        starter = 1\n",
    "    \n",
    "    for oik in list(oik_links.keys())[counter:]:\n",
    "        oik_tik[oik] = {}\n",
    "        o_href = oik_links[oik]\n",
    "        tik_links = getLinksFromPivot(o_href)\n",
    "        if tik_links:\n",
    "            for tik in tik_links:\n",
    "                t_href = tik_links[tik]\n",
    "                table_link = bridgeToLocal(t_href)\n",
    "                oik_tik[oik][tik] = getTable(table_link, positions)\n",
    "        else:\n",
    "            tik = '-'\n",
    "            table_link = bridgeToLocal(o_href)\n",
    "            oik_tik[oik][tik] = getTable(table_link, positions)\n",
    "        \n",
    "        if starter == 0:\n",
    "                    meta = getMeta(table_link, positions)\n",
    "                    headers = [\"ОИК\", \"ТИК\", \"УИК\"]\n",
    "                    headers.extend(meta)\n",
    "                    fill.write(';'.join(headers))\n",
    "                    fill.write('\\n')\n",
    "                    fill.close()\n",
    "                    starter = 1\n",
    "        \n",
    "        updateTable(oik, oik_tik)\n",
    "        counter += 1\n",
    "        print('%s\\t%s' % (str(counter), oik))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "135\tТерритория за пределами РФ\n"
     ]
    }
   ],
   "source": [
    "main(counter=134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
